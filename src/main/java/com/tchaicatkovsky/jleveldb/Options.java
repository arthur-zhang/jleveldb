/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.tchaicatkovsky.jleveldb;

import com.tchaicatkovsky.jleveldb.util.BytewiseComparatorImpl;
import com.tchaicatkovsky.jleveldb.util.Cache;
import com.tchaicatkovsky.jleveldb.util.Comparator0;

public class Options {

	/**
	 * Parameters that affect behavior
	 */

	/**
	 * Comparator used to define the order of keys in the table.</br>
	 * </br>
	 * Default: a comparator that uses lexicographic byte-wise ordering</br>
	 * </br>
	 * </br>
	 * 
	 * REQUIRES: The client must ensure that the comparator supplied here has the same name and orders keys *exactly* the same as the comparator provided to previous open calls on the same DB.
	 */
	public Comparator0 comparator;

	/**
	 * If {@code true}, the database will be created if it is missing.</br>
	 * </br>
	 * Default: {@code false}
	 */
	public boolean createIfMissing;

	/**
	 * If {@code true}, an error is raised if the database already exists.</br>
	 * </br>
	 * Default: {@code false}
	 */
	public boolean errorIfExists;

	/**
	 * If true, the implementation will do aggressive checking of the data it is processing and will stop early if it detects any errors.</br>
	 * </br>
	 * 
	 * This may have unforeseen ramifications: for example, a corruption of one DB entry may cause a large number of entries to become unreadable or for the entire DB to become unopenable.</br>
	 * </br>
	 * 
	 * Default: {@code false}
	 */
	public boolean paranoidChecks;

	/**
	 * Use the specified object to interact with the environment, e.g. to read/write files, schedule background work, etc.</br>
	 * </br>
	 * 
	 * Default: {@link Env.defaultInstance}
	 */
	public Env env;

	/**
	 * Any internal progress/error information generated by the db will be written to infoLog if it is non-NULL, or to a file stored in the same directory as the DB contents if infoLog is null.</br>
	 * </br>
	 * 
	 * Default: {@code null}
	 */
	public Logger0 infoLog;

	/**
	 * Parameters that affect performance
	 */

	/**
	 * Amount of data to build up in memory (backed by an unsorted log on disk) before converting to a sorted on-disk file.</br>
	 * </br>
	 * 
	 * Larger values increase performance, especially during bulk loads. Up to two write buffers may be held in memory at the same time, so you may wish to adjust this parameter to control memory
	 * usage. Also, a larger write buffer will result in a longer recovery time the next time the database is opened.</br>
	 * </br>
	 * 
	 * Default: 4MB
	 */
	public int writeBufferSize;

	/**
	 * Number of open files that can be used by the DB. You may need to increase this if your database has a large working set (budget one open file per 2MB of working set).</br>
	 * </br>
	 *
	 * Default: 1000
	 */
	public int maxOpenFiles;

	/**
	 * Control over blocks (user data is stored in a set of blocks, and a block is the unit of reading from disk).</br>
	 * </br>
	 *
	 * If {@code non-null}, use the specified cache for blocks.</br>
	 * If {@code null}, jleveldb will automatically create and use an 8MB internal cache.</br>
	 * </br>
	 * 
	 * Default: {@code null}
	 */
	public Cache blockCache;

	/**
	 * Approximate size of user data packed per block.</br>
	 * Note that the block size specified here corresponds to uncompressed data.</br>
	 * The actual size of the unit read from disk may be smaller if compression is enabled. This parameter can be changed dynamically.</br>
	 * </br>
	 *
	 * Default: 4K
	 */
	public int blockSize;

	/**
	 * Number of keys between restart points for delta encoding of keys. This parameter can be changed dynamically. Most clients should leave this parameter alone.</br>
	 * </br>
	 * 
	 * Default: 16
	 */
	public int blockRestartInterval;

	/**
	 * jleveldb will write up to this amount of bytes to a file before switching to a new one.</br>
	 * </br>
	 * Most clients should leave this parameter alone. However if your filesystem is more efficient with larger files, you could consider increasing the value.</br>
	 * </br>
	 * The downside will be longer compactions and hence longer latency/performance hiccups.</br>
	 * </br>
	 * Another reason to increase this parameter might be when you are initially populating a large database.</br>
	 * </br>
	 * </br>
	 *
	 * Default: 2MB
	 */
	public int maxFileSize;

	/**
	 * Compress blocks using the specified compression algorithm. This parameter can be changed dynamically.</br>
	 * </br>
	 * 
	 * Default: {@link CompressionType.SnappyCompression}, which gives lightweight but fast compression.</br>
	 * </br>
	 * 
	 * Typical speeds of SnappyCompression on an Intel(R) Core(TM)2 2.4GHz:</br>
	 * ~200-500MB/s compression</br>
	 * ~400-800MB/s decompression</br>
	 * </br>
	 * Note that these speeds are significantly faster than most persistent storage speeds, and therefore it is typically never worth switching to kNoCompression. Even if the input data is
	 * incompressible, the kSnappyCompression implementation will efficiently detect that and will switch to uncompressed mode.
	 */
	public CompressionType compression;

	/**
	 * EXPERIMENTAL: If true, append to existing MANIFEST and log files when a database is opened. This can significantly speed up open.</br>
	 * </br>
	 * 
	 * Default: currently false, but may become true later.
	 */
	public boolean reuseLogs;

	/**
	 * If non-null, use the specified filter policy to reduce disk reads. Many applications will benefit from passing the result of NewBloomFilterPolicy() here.</br>
	 * </br>
	 *
	 * Default: null
	 */
	public FilterPolicy filterPolicy;

	public Options(Comparator0 comparator) {
		this();
		this.comparator = comparator;
	}

	public Options() {
		comparator = BytewiseComparatorImpl.getInstance();
		createIfMissing = false;
		errorIfExists = false;
		paranoidChecks = false;
		env = LevelDB.defaultEnv();
		infoLog = null;

		writeBufferSize = 4 * 1024 * 1024;
		maxOpenFiles = 1000;
		blockCache = null;
		blockSize = 4 * 1024;
		blockRestartInterval = 16;
		maxFileSize = 2 * 1024 * 1024;
		compression = CompressionType.kSnappyCompression;

		reuseLogs = false;
		filterPolicy = null;
	}

	public Options cloneOptions() {
		Options ret = new Options(comparator);

		ret.createIfMissing = createIfMissing;
		ret.errorIfExists = errorIfExists;
		ret.paranoidChecks = paranoidChecks;
		ret.env = env;
		ret.infoLog = infoLog;

		ret.writeBufferSize = writeBufferSize;
		ret.maxOpenFiles = maxOpenFiles;
		ret.blockCache = blockCache;
		ret.blockSize = blockSize;
		ret.blockRestartInterval = blockRestartInterval;
		ret.maxFileSize = maxFileSize;
		ret.compression = compression;

		ret.reuseLogs = reuseLogs;
		ret.filterPolicy = filterPolicy;

		return ret;
	}
}
